# RagCode MCP Server

<!-- AI Agents: This is the summarized documentation for RagCode. For full details, see llms-full.txt -->

> Privacy-first MCP server for semantic code search using RAG. Runs 100% locally.

## Why RagCode?

- **5-10x faster** code understanding vs. reading files manually
- **98% token savings** - returns only relevant code, not entire files
- **Zero cost** - no API fees, runs on local Ollama + Qdrant
- **Privacy-first** - code never leaves your machine

## Compatibility

- **IDEs:** Windsurf, Cursor, VS Code + GitHub Copilot, Claude Desktop, Antigravity
- **Languages:** Go, PHP (Laravel), Python, JavaScript
- **OS:** Linux (amd64) - macOS/Windows coming soon

## Quick Install (Linux)

**Option A: Everything in Docker (recommended)**
```bash
curl -fsSL https://github.com/doITmagic/rag-code-mcp/releases/latest/download/rag-code-mcp_linux_amd64.tar.gz | tar xz && ./ragcode-installer -ollama=docker -qdrant=docker
```

**Option B: Local Ollama + Docker Qdrant**
```bash
curl -fsSL https://ollama.com/install.sh | sh  # Install Ollama first
curl -fsSL https://github.com/doITmagic/rag-code-mcp/releases/latest/download/rag-code-mcp_linux_amd64.tar.gz | tar xz && ./ragcode-installer -ollama=local -qdrant=docker
```

Key flags: `-ollama` (docker/local), `-qdrant` (docker/remote), `-gpu`, `-models-dir`, `-skip-build`

## Example Usage

User: "Find authentication middleware in this codebase"
→ RagCode uses `search_code` tool
→ Returns exact functions with file paths and line numbers
→ AI can now reason about the code without reading 50 files

## 9 MCP Tools

1. `search_code` - Semantic search across the codebase
2. `hybrid_search` - Combined semantic + lexical search
3. `get_function_details` - Get function signature and body
4. `find_type_definition` - Find struct/interface definitions
5. `find_implementations` - Find usages of a symbol
6. `list_package_exports` - List exported symbols from a package
7. `search_docs` - Search markdown documentation
8. `get_code_context` - Read code with surrounding context
9. `index_workspace` - Manual indexing (usually automatic)

## Configuration

Config file: `~/.local/share/ragcode/config.yaml`

```yaml
llm:
  provider: "ollama"
  model: "phi3:medium"
  embed_model: "nomic-embed-text"

storage:
  vector_db:
    url: "http://localhost:6333"
```

## Status

✅ Production-ready | ✅ Active development | ✅ MIT License

## Links

- GitHub: https://github.com/doITmagic/rag-code-mcp
- Full docs: https://github.com/doITmagic/rag-code-mcp/blob/main/llms-full.txt

## Keywords

semantic-code-search, rag, retrieval-augmented-generation, mcp-server, model-context-protocol, ai-code-assistant, vector-search, code-navigation, ollama, qdrant, github-copilot, cursor-ai, windsurf, local-ai, privacy-first, offline-ai, self-hosted, zero-cost
